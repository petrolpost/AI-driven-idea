# æ··åˆæ¶æ„ç¤ºä¾‹ä¸æœ€ä½³å®è·µ

æœ¬æ–‡æ¡£æä¾›æ··åˆæ¶æ„çš„å…·ä½“å®ç°ç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•å·§å¦™ç»“åˆå·¥ä½œæµçš„å¯é æ€§å’Œæ™ºèƒ½ä½“çš„çµæ´»æ€§ï¼Œæ„å»ºæ—¢ç¨³å®šåˆæ™ºèƒ½çš„AIç³»ç»Ÿã€‚

## ğŸ”„ æ··åˆæ¶æ„æ ¸å¿ƒç†å¿µ

æ··åˆæ¶æ„çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **ç»“æ„åŒ–ä»»åŠ¡ä½¿ç”¨å·¥ä½œæµ**ï¼šç¡®ä¿å…³é”®ä¸šåŠ¡æµç¨‹çš„å¯é æ€§å’Œä¸€è‡´æ€§
- **å¼€æ”¾æ€§ä»»åŠ¡ä½¿ç”¨æ™ºèƒ½ä½“**ï¼šå¤„ç†éœ€è¦åˆ›é€ æ€§å’Œé€‚åº”æ€§çš„å¤æ‚é—®é¢˜
- **æ™ºèƒ½è·¯ç”±æœºåˆ¶**ï¼šæ ¹æ®ä»»åŠ¡ç‰¹æ€§è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„å¤„ç†æ–¹å¼
- **æ— ç¼é›†æˆ**ï¼šå·¥ä½œæµå’Œæ™ºèƒ½ä½“ä¹‹é—´å¯ä»¥ç›¸äº’è°ƒç”¨å’Œåä½œ

## ğŸ—ï¸ æ··åˆæ¶æ„æ¡†æ¶

### æ ¸å¿ƒæ¶æ„ç±»

```python
from typing import Dict, Any, List, Optional, Union
from dataclasses import dataclass
from enum import Enum
import logging
from datetime import datetime
from abc import ABC, abstractmethod

class ProcessingMode(Enum):
    """å¤„ç†æ¨¡å¼"""
    WORKFLOW = "workflow"
    AGENT = "agent"
    HYBRID = "hybrid"
    AUTO = "auto"

class TaskComplexity(Enum):
    """ä»»åŠ¡å¤æ‚åº¦"""
    SIMPLE = "simple"          # ç®€å•ç»“æ„åŒ–ä»»åŠ¡
    MODERATE = "moderate"      # ä¸­ç­‰å¤æ‚åº¦ä»»åŠ¡
    COMPLEX = "complex"        # å¤æ‚å¼€æ”¾æ€§ä»»åŠ¡
    DYNAMIC = "dynamic"        # åŠ¨æ€å˜åŒ–ä»»åŠ¡

@dataclass
class TaskClassification:
    """ä»»åŠ¡åˆ†ç±»ç»“æœ"""
    complexity: TaskComplexity
    structure_level: float      # ç»“æ„åŒ–ç¨‹åº¦ (0-1)
    creativity_required: float  # åˆ›é€ æ€§éœ€æ±‚ (0-1)
    uncertainty_level: float    # ä¸ç¡®å®šæ€§æ°´å¹³ (0-1)
    recommended_mode: ProcessingMode
    confidence: float

class HybridProcessor:
    """æ··åˆå¤„ç†å™¨ - æ ¸å¿ƒåè°ƒç»„ä»¶"""
    
    def __init__(self, llm_client):
        self.llm_client = llm_client
        self.workflows = {}  # æ³¨å†Œçš„å·¥ä½œæµ
        self.agents = {}     # æ³¨å†Œçš„æ™ºèƒ½ä½“
        self.task_classifier = TaskClassifier(llm_client)
        self.router = TaskRouter()
        self.logger = logging.getLogger("hybrid_processor")
        
        # æ€§èƒ½æŒ‡æ ‡
        self.metrics = {
            'total_tasks': 0,
            'workflow_tasks': 0,
            'agent_tasks': 0,
            'hybrid_tasks': 0,
            'success_rate': 0.0
        }
    
    def register_workflow(self, name: str, workflow):
        """æ³¨å†Œå·¥ä½œæµ"""
        self.workflows[name] = workflow
        self.logger.info(f"æ³¨å†Œå·¥ä½œæµ: {name}")
    
    def register_agent(self, name: str, agent):
        """æ³¨å†Œæ™ºèƒ½ä½“"""
        self.agents[name] = agent
        self.logger.info(f"æ³¨å†Œæ™ºèƒ½ä½“: {name}")
    
    def process_task(self, task: str, context: Dict[str, Any] = None, 
                    mode: ProcessingMode = ProcessingMode.AUTO) -> Dict[str, Any]:
        """å¤„ç†ä»»åŠ¡çš„ä¸»å…¥å£"""
        start_time = datetime.now()
        self.metrics['total_tasks'] += 1
        
        try:
            # ä»»åŠ¡åˆ†ç±»
            classification = self.task_classifier.classify_task(task, context)
            
            # ç¡®å®šå¤„ç†æ¨¡å¼
            if mode == ProcessingMode.AUTO:
                processing_mode = classification.recommended_mode
            else:
                processing_mode = mode
            
            # è·¯ç”±åˆ°ç›¸åº”çš„å¤„ç†å™¨
            result = self.router.route_task(
                task=task,
                context=context,
                mode=processing_mode,
                classification=classification,
                workflows=self.workflows,
                agents=self.agents
            )
            
            # æ›´æ–°æŒ‡æ ‡
            self._update_metrics(processing_mode, True)
            
            # æ·»åŠ å…ƒæ•°æ®
            result.update({
                'processing_mode': processing_mode.value,
                'classification': classification,
                'execution_time': (datetime.now() - start_time).total_seconds()
            })
            
            return result
            
        except Exception as e:
            self._update_metrics(processing_mode, False)
            self.logger.error(f"ä»»åŠ¡å¤„ç†å¤±è´¥: {str(e)}")
            
            return {
                'success': False,
                'error': str(e),
                'processing_mode': processing_mode.value if 'processing_mode' in locals() else 'unknown',
                'execution_time': (datetime.now() - start_time).total_seconds()
            }
    
    def _update_metrics(self, mode: ProcessingMode, success: bool):
        """æ›´æ–°æ€§èƒ½æŒ‡æ ‡"""
        if mode == ProcessingMode.WORKFLOW:
            self.metrics['workflow_tasks'] += 1
        elif mode == ProcessingMode.AGENT:
            self.metrics['agent_tasks'] += 1
        elif mode == ProcessingMode.HYBRID:
            self.metrics['hybrid_tasks'] += 1
        
        # æ›´æ–°æˆåŠŸç‡
        total = self.metrics['total_tasks']
        current_success = self.metrics['success_rate'] * (total - 1)
        if success:
            current_success += 1
        self.metrics['success_rate'] = current_success / total

class TaskClassifier:
    """ä»»åŠ¡åˆ†ç±»å™¨"""
    
    def __init__(self, llm_client):
        self.llm_client = llm_client
    
    def classify_task(self, task: str, context: Dict[str, Any] = None) -> TaskClassification:
        """åˆ†ç±»ä»»åŠ¡"""
        classification_prompt = f"""
        åˆ†æä»¥ä¸‹ä»»åŠ¡ï¼Œè¯„ä¼°å…¶ç‰¹å¾å¹¶æ¨èæœ€é€‚åˆçš„å¤„ç†æ¨¡å¼ï¼š
        
        ä»»åŠ¡: {task}
        ä¸Šä¸‹æ–‡: {context or {}}
        
        è¯·è¯„ä¼°ä»¥ä¸‹ç»´åº¦ï¼ˆ0-1åˆ†ï¼‰ï¼š
        1. ç»“æ„åŒ–ç¨‹åº¦ (structure_level): ä»»åŠ¡æ˜¯å¦æœ‰æ˜ç¡®çš„æ­¥éª¤å’Œè§„åˆ™
        2. åˆ›é€ æ€§éœ€æ±‚ (creativity_required): æ˜¯å¦éœ€è¦åˆ›æ–°æ€ç»´å’Œçµæ´»åº”å¯¹
        3. ä¸ç¡®å®šæ€§æ°´å¹³ (uncertainty_level): ä»»åŠ¡çš„å˜åŒ–æ€§å’Œä¸å¯é¢„æµ‹æ€§
        
        åŸºäºè¯„ä¼°ç»“æœï¼Œæ¨èå¤„ç†æ¨¡å¼ï¼š
        - workflow: é«˜ç»“æ„åŒ–ã€ä½åˆ›é€ æ€§ã€ä½ä¸ç¡®å®šæ€§
        - agent: ä½ç»“æ„åŒ–ã€é«˜åˆ›é€ æ€§ã€é«˜ä¸ç¡®å®šæ€§
        - hybrid: ä¸­ç­‰æ°´å¹³æˆ–éœ€è¦ç»“åˆä¸¤ç§æ–¹å¼
        
        è¯·ä»¥JSONæ ¼å¼è¿”å›è¯„ä¼°ç»“æœï¼š
        {{
            "structure_level": 0.8,
            "creativity_required": 0.3,
            "uncertainty_level": 0.2,
            "complexity": "simple|moderate|complex|dynamic",
            "recommended_mode": "workflow|agent|hybrid",
            "confidence": 0.9,
            "reasoning": "æ¨èç†ç”±"
        }}
        """
        
        response = self.llm_client.complete(classification_prompt)
        
        try:
            import json
            result = json.loads(response)
            
            return TaskClassification(
                complexity=TaskComplexity(result['complexity']),
                structure_level=result['structure_level'],
                creativity_required=result['creativity_required'],
                uncertainty_level=result['uncertainty_level'],
                recommended_mode=ProcessingMode(result['recommended_mode']),
                confidence=result['confidence']
            )
            
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            # é»˜è®¤åˆ†ç±»
            return TaskClassification(
                complexity=TaskComplexity.MODERATE,
                structure_level=0.5,
                creativity_required=0.5,
                uncertainty_level=0.5,
                recommended_mode=ProcessingMode.HYBRID,
                confidence=0.3
            )

class TaskRouter:
    """ä»»åŠ¡è·¯ç”±å™¨"""
    
    def route_task(self, task: str, context: Dict[str, Any], 
                  mode: ProcessingMode, classification: TaskClassification,
                  workflows: Dict, agents: Dict) -> Dict[str, Any]:
        """è·¯ç”±ä»»åŠ¡åˆ°åˆé€‚çš„å¤„ç†å™¨"""
        
        if mode == ProcessingMode.WORKFLOW:
            return self._route_to_workflow(task, context, workflows, classification)
        
        elif mode == ProcessingMode.AGENT:
            return self._route_to_agent(task, context, agents, classification)
        
        elif mode == ProcessingMode.HYBRID:
            return self._route_to_hybrid(task, context, workflows, agents, classification)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¤„ç†æ¨¡å¼: {mode}")
    
    def _route_to_workflow(self, task: str, context: Dict[str, Any], 
                          workflows: Dict, classification: TaskClassification) -> Dict[str, Any]:
        """è·¯ç”±åˆ°å·¥ä½œæµ"""
        # é€‰æ‹©æœ€åˆé€‚çš„å·¥ä½œæµ
        selected_workflow = self._select_best_workflow(task, workflows, classification)
        
        if not selected_workflow:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„å·¥ä½œæµ")
        
        # æ‰§è¡Œå·¥ä½œæµ
        result = selected_workflow.execute({
            'task': task,
            **context
        })
        
        return {
            'success': result.success,
            'response': result.data,
            'workflow_used': selected_workflow.name,
            'step_results': result.step_results
        }
    
    def _route_to_agent(self, task: str, context: Dict[str, Any], 
                       agents: Dict, classification: TaskClassification) -> Dict[str, Any]:
        """è·¯ç”±åˆ°æ™ºèƒ½ä½“"""
        # é€‰æ‹©æœ€åˆé€‚çš„æ™ºèƒ½ä½“
        selected_agent = self._select_best_agent(task, agents, classification)
        
        if not selected_agent:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„æ™ºèƒ½ä½“")
        
        # æ‰§è¡Œæ™ºèƒ½ä½“ä»»åŠ¡
        result = selected_agent.process_request(task, context)
        
        return {
            'success': result.get('success', True),
            'response': result.get('response', ''),
            'agent_used': selected_agent.name,
            'reasoning_steps': result.get('reasoning_steps', 0),
            'tools_used': result.get('tools_used', [])
        }
    
    def _route_to_hybrid(self, task: str, context: Dict[str, Any], 
                        workflows: Dict, agents: Dict, 
                        classification: TaskClassification) -> Dict[str, Any]:
        """è·¯ç”±åˆ°æ··åˆå¤„ç†"""
        # åˆ†è§£ä»»åŠ¡ä¸ºç»“æ„åŒ–å’Œå¼€æ”¾æ€§éƒ¨åˆ†
        task_decomposition = self._decompose_task(task, classification)
        
        results = []
        
        for subtask in task_decomposition['subtasks']:
            if subtask['type'] == 'structured':
                # ä½¿ç”¨å·¥ä½œæµå¤„ç†ç»“æ„åŒ–éƒ¨åˆ†
                workflow_result = self._route_to_workflow(
                    subtask['description'], context, workflows, classification
                )
                results.append({
                    'subtask': subtask,
                    'processor': 'workflow',
                    'result': workflow_result
                })
            
            elif subtask['type'] == 'creative':
                # ä½¿ç”¨æ™ºèƒ½ä½“å¤„ç†åˆ›é€ æ€§éƒ¨åˆ†
                agent_result = self._route_to_agent(
                    subtask['description'], context, agents, classification
                )
                results.append({
                    'subtask': subtask,
                    'processor': 'agent',
                    'result': agent_result
                })
        
        # æ•´åˆç»“æœ
        integrated_result = self._integrate_hybrid_results(results, task)
        
        return {
            'success': all(r['result']['success'] for r in results),
            'response': integrated_result,
            'hybrid_breakdown': results,
            'integration_method': 'sequential'
        }
    
    def _decompose_task(self, task: str, classification: TaskClassification) -> Dict[str, Any]:
        """åˆ†è§£ä»»åŠ¡ä¸ºå­ä»»åŠ¡"""
        # è¿™é‡Œå¯ä»¥ä½¿ç”¨LLMæ¥æ™ºèƒ½åˆ†è§£ä»»åŠ¡
        # ç®€åŒ–ç¤ºä¾‹
        return {
            'subtasks': [
                {
                    'type': 'structured',
                    'description': f"å¤„ç† {task} çš„æ ‡å‡†åŒ–éƒ¨åˆ†",
                    'priority': 1
                },
                {
                    'type': 'creative',
                    'description': f"ä¸º {task} æä¾›åˆ›æ–°æ€§å»ºè®®",
                    'priority': 2
                }
            ]
        }
```

## ğŸ¯ å®é™…åº”ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šæ™ºèƒ½å®¢æœç³»ç»Ÿ

```python
class IntelligentCustomerServiceSystem(HybridProcessor):
    """æ™ºèƒ½å®¢æœæ··åˆç³»ç»Ÿ"""
    
    def __init__(self, llm_client):
        super().__init__(llm_client)
        
        # æ³¨å†Œæ ‡å‡†å®¢æœå·¥ä½œæµ
        self.register_workflow('billing_inquiry', BillingInquiryWorkflow())
        self.register_workflow('order_status', OrderStatusWorkflow())
        self.register_workflow('return_process', ReturnProcessWorkflow())
        
        # æ³¨å†Œä¸“ä¸šæ™ºèƒ½ä½“
        self.register_agent('technical_support', TechnicalSupportAgent(llm_client))
        self.register_agent('complaint_handler', ComplaintHandlerAgent(llm_client))
        self.register_agent('sales_assistant', SalesAssistantAgent(llm_client))
        
        # é…ç½®è·¯ç”±è§„åˆ™
        self.setup_routing_rules()
    
    def setup_routing_rules(self):
        """è®¾ç½®è·¯ç”±è§„åˆ™"""
        self.routing_rules = {
            'keywords': {
                'billing': 'billing_inquiry',
                'order': 'order_status',
                'return': 'return_process',
                'technical': 'technical_support',
                'complaint': 'complaint_handler',
                'buy': 'sales_assistant'
            },
            'patterns': {
                r'è®¢å•å·.*\d+': 'order_status',
                r'è´¦å•.*é—®é¢˜': 'billing_inquiry',
                r'æŠ€æœ¯.*æ”¯æŒ': 'technical_support'
            }
        }
    
    def handle_customer_inquiry(self, customer_message: str, 
                              customer_info: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å®¢æˆ·å’¨è¯¢"""
        
        # é¢„å¤„ç†ï¼šæå–å…³é”®ä¿¡æ¯
        extracted_info = self.extract_inquiry_info(customer_message)
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context = {
            'customer_info': customer_info,
            'extracted_info': extracted_info,
            'channel': 'web_chat',
            'timestamp': datetime.now().isoformat()
        }
        
        # ä½¿ç”¨æ··åˆå¤„ç†å™¨å¤„ç†
        result = self.process_task(customer_message, context)
        
        # åå¤„ç†ï¼šæ ¼å¼åŒ–å“åº”
        formatted_response = self.format_customer_response(result)
        
        # è®°å½•äº¤äº’
        self.log_customer_interaction(customer_info, customer_message, formatted_response)
        
        return formatted_response
    
    def extract_inquiry_info(self, message: str) -> Dict[str, Any]:
        """æå–å’¨è¯¢ä¿¡æ¯"""
        extraction_prompt = f"""
        ä»ä»¥ä¸‹å®¢æˆ·æ¶ˆæ¯ä¸­æå–å…³é”®ä¿¡æ¯ï¼š
        
        æ¶ˆæ¯: {message}
        
        è¯·æå–ï¼š
        1. å’¨è¯¢ç±»å‹ (billing/order/technical/complaint/sales/general)
        2. ç´§æ€¥ç¨‹åº¦ (low/medium/high)
        3. å…³é”®å®ä½“ (è®¢å•å·ã€äº§å“åç§°ç­‰)
        4. æƒ…æ„Ÿå€¾å‘ (positive/neutral/negative)
        
        ä»¥JSONæ ¼å¼è¿”å›ã€‚
        """
        
        response = self.llm_client.complete(extraction_prompt)
        
        try:
            import json
            return json.loads(response)
        except json.JSONDecodeError:
            return {
                'inquiry_type': 'general',
                'urgency': 'medium',
                'entities': [],
                'sentiment': 'neutral'
            }
```

### ç¤ºä¾‹2ï¼šå†…å®¹åˆ›ä½œå¹³å°

```python
class ContentCreationPlatform(HybridProcessor):
    """å†…å®¹åˆ›ä½œæ··åˆå¹³å°"""
    
    def __init__(self, llm_client):
        super().__init__(llm_client)
        
        # æ³¨å†Œæ ‡å‡†åŒ–å†…å®¹å·¥ä½œæµ
        self.register_workflow('seo_article', SEOArticleWorkflow())
        self.register_workflow('product_description', ProductDescriptionWorkflow())
        self.register_workflow('social_media_post', SocialMediaPostWorkflow())
        
        # æ³¨å†Œåˆ›æ„æ™ºèƒ½ä½“
        self.register_agent('creative_writer', CreativeWriterAgent(llm_client))
        self.register_agent('brand_strategist', BrandStrategistAgent(llm_client))
        self.register_agent('content_optimizer', ContentOptimizerAgent(llm_client))
    
    def create_content(self, content_brief: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºå†…å®¹"""
        
        content_type = content_brief.get('type', '')
        requirements = content_brief.get('requirements', {})
        
        # åˆ†æå†…å®¹éœ€æ±‚
        content_analysis = self.analyze_content_requirements(content_brief)
        
        # æ ¹æ®åˆ†æç»“æœé€‰æ‹©å¤„ç†æ–¹å¼
        if content_analysis['standardization_level'] > 0.7:
            # é«˜åº¦æ ‡å‡†åŒ–å†…å®¹ï¼Œä½¿ç”¨å·¥ä½œæµ
            result = self.process_task(
                f"åˆ›å»º{content_type}å†…å®¹",
                content_brief,
                ProcessingMode.WORKFLOW
            )
        
        elif content_analysis['creativity_requirement'] > 0.7:
            # é«˜åˆ›æ„è¦æ±‚ï¼Œä½¿ç”¨æ™ºèƒ½ä½“
            result = self.process_task(
                f"åˆ›ä½œ{content_type}å†…å®¹",
                content_brief,
                ProcessingMode.AGENT
            )
        
        else:
            # æ··åˆéœ€æ±‚ï¼Œä½¿ç”¨æ··åˆæ¨¡å¼
            result = self.process_task(
                f"åˆ¶ä½œ{content_type}å†…å®¹",
                content_brief,
                ProcessingMode.HYBRID
            )
        
        # è´¨é‡æ£€æŸ¥å’Œä¼˜åŒ–
        if result['success']:
            optimized_content = self.optimize_content(result['response'], requirements)
            result['response'] = optimized_content
        
        return result
    
    def analyze_content_requirements(self, brief: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå†…å®¹éœ€æ±‚"""
        analysis_prompt = f"""
        åˆ†æä»¥ä¸‹å†…å®¹åˆ›ä½œéœ€æ±‚ï¼š
        
        å†…å®¹ç®€ä»‹: {brief}
        
        è¯·è¯„ä¼°ï¼š
        1. æ ‡å‡†åŒ–ç¨‹åº¦ (0-1): å†…å®¹æ˜¯å¦æœ‰å›ºå®šæ¨¡æ¿å’Œæ ¼å¼
        2. åˆ›æ„è¦æ±‚ (0-1): æ˜¯å¦éœ€è¦ç‹¬ç‰¹çš„åˆ›æ„å’Œä¸ªæ€§åŒ–
        3. æŠ€æœ¯å¤æ‚åº¦ (0-1): å†…å®¹åˆ›ä½œçš„æŠ€æœ¯éš¾åº¦
        4. æ—¶æ•ˆæ€§è¦æ±‚ (0-1): å¯¹åˆ›ä½œé€Ÿåº¦çš„è¦æ±‚
        
        ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
        """
        
        response = self.llm_client.complete(analysis_prompt)
        
        try:
            import json
            return json.loads(response)
        except json.JSONDecodeError:
            return {
                'standardization_level': 0.5,
                'creativity_requirement': 0.5,
                'technical_complexity': 0.5,
                'urgency_level': 0.5
            }
```

### ç¤ºä¾‹3ï¼šæ™ºèƒ½æ•°æ®åˆ†æç³»ç»Ÿ

```python
class IntelligentDataAnalysisSystem(HybridProcessor):
    """æ™ºèƒ½æ•°æ®åˆ†ææ··åˆç³»ç»Ÿ"""
    
    def __init__(self, llm_client):
        super().__init__(llm_client)
        
        # æ³¨å†Œæ ‡å‡†åˆ†æå·¥ä½œæµ
        self.register_workflow('sales_report', SalesReportWorkflow())
        self.register_workflow('user_behavior', UserBehaviorWorkflow())
        self.register_workflow('financial_analysis', FinancialAnalysisWorkflow())
        
        # æ³¨å†Œåˆ†ææ™ºèƒ½ä½“
        self.register_agent('data_scientist', DataScientistAgent(llm_client))
        self.register_agent('business_analyst', BusinessAnalystAgent(llm_client))
        self.register_agent('insight_generator', InsightGeneratorAgent(llm_client))
    
    def analyze_data(self, analysis_request: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ•°æ®"""
        
        data_source = analysis_request.get('data_source', '')
        analysis_type = analysis_request.get('analysis_type', '')
        business_question = analysis_request.get('question', '')
        
        # è¯„ä¼°åˆ†æå¤æ‚åº¦
        complexity_assessment = self.assess_analysis_complexity(analysis_request)
        
        if complexity_assessment['is_standard_report']:
            # æ ‡å‡†æŠ¥å‘Šï¼Œä½¿ç”¨å·¥ä½œæµ
            result = self.process_task(
                f"ç”Ÿæˆ{analysis_type}æŠ¥å‘Š",
                analysis_request,
                ProcessingMode.WORKFLOW
            )
        
        elif complexity_assessment['requires_exploration']:
            # æ¢ç´¢æ€§åˆ†æï¼Œä½¿ç”¨æ™ºèƒ½ä½“
            result = self.process_task(
                f"æ¢ç´¢æ€§åˆ†æï¼š{business_question}",
                analysis_request,
                ProcessingMode.AGENT
            )
        
        else:
            # æ··åˆåˆ†æéœ€æ±‚
            result = self.process_task(
                f"ç»¼åˆåˆ†æï¼š{business_question}",
                analysis_request,
                ProcessingMode.HYBRID
            )
        
        # ç”Ÿæˆå¯è§†åŒ–å»ºè®®
        if result['success']:
            visualization_suggestions = self.suggest_visualizations(result['response'])
            result['visualizations'] = visualization_suggestions
        
        return result
    
    def assess_analysis_complexity(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°åˆ†æå¤æ‚åº¦"""
        # ç®€åŒ–çš„å¤æ‚åº¦è¯„ä¼°é€»è¾‘
        analysis_type = request.get('analysis_type', '').lower()
        
        standard_reports = ['sales', 'revenue', 'user_count', 'conversion']
        is_standard = any(report in analysis_type for report in standard_reports)
        
        exploratory_keywords = ['why', 'how', 'predict', 'trend', 'correlation']
        requires_exploration = any(keyword in request.get('question', '').lower() 
                                 for keyword in exploratory_keywords)
        
        return {
            'is_standard_report': is_standard,
            'requires_exploration': requires_exploration,
            'data_complexity': len(request.get('data_sources', [])),
            'time_sensitivity': request.get('urgency', 'medium')
        }
```

## ğŸ”§ é«˜çº§æ··åˆæ¨¡å¼

### åŠ¨æ€åˆ‡æ¢æ¨¡å¼

```python
class DynamicHybridProcessor(HybridProcessor):
    """æ”¯æŒåŠ¨æ€åˆ‡æ¢çš„æ··åˆå¤„ç†å™¨"""
    
    def __init__(self, llm_client):
        super().__init__(llm_client)
        self.performance_monitor = PerformanceMonitor()
        self.adaptation_threshold = 0.8  # æ€§èƒ½é˜ˆå€¼
    
    def process_task_with_adaptation(self, task: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """å¸¦è‡ªé€‚åº”çš„ä»»åŠ¡å¤„ç†"""
        
        # åˆå§‹åˆ†ç±»å’Œå¤„ç†
        initial_result = self.process_task(task, context)
        
        # è¯„ä¼°ç»“æœè´¨é‡
        quality_score = self.evaluate_result_quality(initial_result, task)
        
        # å¦‚æœè´¨é‡ä¸è¾¾æ ‡ï¼Œå°è¯•å…¶ä»–æ¨¡å¼
        if quality_score < self.adaptation_threshold:
            self.logger.info(f"åˆå§‹å¤„ç†è´¨é‡ä¸è¾¾æ ‡({quality_score:.2f})ï¼Œå°è¯•å…¶ä»–æ¨¡å¼")
            
            # è·å–åˆå§‹ä½¿ç”¨çš„æ¨¡å¼
            initial_mode = ProcessingMode(initial_result.get('processing_mode', 'auto'))
            
            # å°è¯•å…¶ä»–æ¨¡å¼
            alternative_modes = self.get_alternative_modes(initial_mode)
            
            for alt_mode in alternative_modes:
                alt_result = self.process_task(task, context, alt_mode)
                alt_quality = self.evaluate_result_quality(alt_result, task)
                
                if alt_quality > quality_score:
                    self.logger.info(f"æ‰¾åˆ°æ›´å¥½çš„å¤„ç†æ¨¡å¼: {alt_mode.value} (è´¨é‡: {alt_quality:.2f})")
                    return alt_result
        
        return initial_result
    
    def get_alternative_modes(self, current_mode: ProcessingMode) -> List[ProcessingMode]:
        """è·å–æ›¿ä»£å¤„ç†æ¨¡å¼"""
        all_modes = [ProcessingMode.WORKFLOW, ProcessingMode.AGENT, ProcessingMode.HYBRID]
        return [mode for mode in all_modes if mode != current_mode]
    
    def evaluate_result_quality(self, result: Dict[str, Any], original_task: str) -> float:
        """è¯„ä¼°ç»“æœè´¨é‡"""
        if not result.get('success', False):
            return 0.0
        
        # ä½¿ç”¨LLMè¯„ä¼°è´¨é‡
        evaluation_prompt = f"""
        è¯„ä¼°ä»¥ä¸‹AIç³»ç»Ÿå¤„ç†ç»“æœçš„è´¨é‡ï¼ˆ0-1åˆ†ï¼‰ï¼š
        
        åŸå§‹ä»»åŠ¡: {original_task}
        å¤„ç†ç»“æœ: {result.get('response', '')}
        
        è¯„ä¼°æ ‡å‡†:
        1. ç›¸å…³æ€§ - ç»“æœæ˜¯å¦å›ç­”äº†åŸå§‹é—®é¢˜
        2. å‡†ç¡®æ€§ - ä¿¡æ¯æ˜¯å¦æ­£ç¡®å’Œå¯é 
        3. å®Œæ•´æ€§ - æ˜¯å¦æä¾›äº†å……åˆ†çš„ä¿¡æ¯
        4. æ¸…æ™°æ€§ - è¡¨è¾¾æ˜¯å¦æ¸…æ™°æ˜“æ‡‚
        
        åªè¿”å›æ•°å­—åˆ†æ•°ï¼Œå¦‚: 0.85
        """
        
        try:
            quality_text = self.llm_client.complete(evaluation_prompt)
            return float(quality_text.strip())
        except (ValueError, AttributeError):
            return 0.5  # é»˜è®¤ä¸­ç­‰è´¨é‡
```

### å¹¶è¡Œæ··åˆå¤„ç†

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class ParallelHybridProcessor(HybridProcessor):
    """æ”¯æŒå¹¶è¡Œå¤„ç†çš„æ··åˆå¤„ç†å™¨"""
    
    def __init__(self, llm_client, max_workers: int = 4):
        super().__init__(llm_client)
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
    
    async def process_task_parallel(self, task: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """å¹¶è¡Œå¤„ç†ä»»åŠ¡"""
        
        # åŒæ—¶ä½¿ç”¨å¤šç§æ¨¡å¼å¤„ç†
        tasks = [
            self.async_process(task, context, ProcessingMode.WORKFLOW),
            self.async_process(task, context, ProcessingMode.AGENT),
            self.async_process(task, context, ProcessingMode.HYBRID)
        ]
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # é€‰æ‹©æœ€ä½³ç»“æœ
        best_result = self.select_best_result(results, task)
        
        return best_result
    
    async def async_process(self, task: str, context: Dict[str, Any], mode: ProcessingMode):
        """å¼‚æ­¥å¤„ç†ä»»åŠ¡"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.executor, 
            self.process_task, 
            task, context, mode
        )
    
    def select_best_result(self, results: List, original_task: str) -> Dict[str, Any]:
        """é€‰æ‹©æœ€ä½³ç»“æœ"""
        valid_results = [r for r in results if isinstance(r, dict) and r.get('success', False)]
        
        if not valid_results:
            return {
                'success': False,
                'error': 'æ‰€æœ‰å¤„ç†æ¨¡å¼éƒ½å¤±è´¥äº†',
                'attempted_modes': len(results)
            }
        
        # è¯„ä¼°æ¯ä¸ªç»“æœçš„è´¨é‡
        scored_results = []
        for result in valid_results:
            quality_score = self.evaluate_result_quality(result, original_task)
            scored_results.append((quality_score, result))
        
        # è¿”å›è´¨é‡æœ€é«˜çš„ç»“æœ
        best_score, best_result = max(scored_results, key=lambda x: x[0])
        best_result['quality_score'] = best_score
        best_result['alternatives_considered'] = len(valid_results)
        
        return best_result
```

## ğŸ“Š æ··åˆæ¶æ„ç›‘æ§

### æ€§èƒ½ç›‘æ§ç³»ç»Ÿ

```python
class HybridSystemMonitor:
    """æ··åˆç³»ç»Ÿç›‘æ§"""
    
    def __init__(self):
        self.metrics = {
            'mode_performance': {},  # å„æ¨¡å¼æ€§èƒ½
            'task_distribution': {},  # ä»»åŠ¡åˆ†å¸ƒ
            'quality_trends': [],     # è´¨é‡è¶‹åŠ¿
            'switching_patterns': []  # æ¨¡å¼åˆ‡æ¢æ¨¡å¼
        }
        self.alerts = []
    
    def track_processing(self, task: str, mode: ProcessingMode, 
                        result: Dict[str, Any], quality_score: float):
        """è·Ÿè¸ªå¤„ç†è¿‡ç¨‹"""
        
        # æ›´æ–°æ¨¡å¼æ€§èƒ½
        mode_key = mode.value
        if mode_key not in self.metrics['mode_performance']:
            self.metrics['mode_performance'][mode_key] = {
                'total_tasks': 0,
                'successful_tasks': 0,
                'average_quality': 0.0,
                'average_time': 0.0
            }
        
        perf = self.metrics['mode_performance'][mode_key]
        perf['total_tasks'] += 1
        
        if result.get('success', False):
            perf['successful_tasks'] += 1
        
        # æ›´æ–°å¹³å‡è´¨é‡
        current_avg_quality = perf['average_quality']
        perf['average_quality'] = (
            (current_avg_quality * (perf['total_tasks'] - 1) + quality_score) / perf['total_tasks']
        )
        
        # æ›´æ–°å¹³å‡æ—¶é—´
        execution_time = result.get('execution_time', 0)
        current_avg_time = perf['average_time']
        perf['average_time'] = (
            (current_avg_time * (perf['total_tasks'] - 1) + execution_time) / perf['total_tasks']
        )
        
        # è®°å½•è´¨é‡è¶‹åŠ¿
        self.metrics['quality_trends'].append({
            'timestamp': datetime.now(),
            'mode': mode_key,
            'quality': quality_score,
            'task_type': self.classify_task_type(task)
        })
        
        # æ£€æŸ¥å‘Šè­¦
        self.check_performance_alerts(mode_key, perf)
    
    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        report = {
            'overall_metrics': self.calculate_overall_metrics(),
            'mode_comparison': self.compare_modes(),
            'quality_trends': self.analyze_quality_trends(),
            'recommendations': self.generate_recommendations()
        }
        
        return report
    
    def calculate_overall_metrics(self) -> Dict[str, Any]:
        """è®¡ç®—æ•´ä½“æŒ‡æ ‡"""
        total_tasks = sum(perf['total_tasks'] for perf in self.metrics['mode_performance'].values())
        total_successful = sum(perf['successful_tasks'] for perf in self.metrics['mode_performance'].values())
        
        if total_tasks == 0:
            return {'success_rate': 0, 'total_tasks': 0}
        
        return {
            'total_tasks': total_tasks,
            'overall_success_rate': total_successful / total_tasks,
            'average_quality': sum(perf['average_quality'] * perf['total_tasks'] 
                                 for perf in self.metrics['mode_performance'].values()) / total_tasks,
            'mode_distribution': {
                mode: perf['total_tasks'] / total_tasks 
                for mode, perf in self.metrics['mode_performance'].items()
            }
        }
    
    def generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # åˆ†ææ¨¡å¼æ€§èƒ½
        mode_performance = self.metrics['mode_performance']
        
        if 'workflow' in mode_performance and 'agent' in mode_performance:
            workflow_quality = mode_performance['workflow']['average_quality']
            agent_quality = mode_performance['agent']['average_quality']
            
            if workflow_quality > agent_quality + 0.1:
                recommendations.append("è€ƒè™‘å¢åŠ å·¥ä½œæµçš„ä½¿ç”¨æ¯”ä¾‹ï¼Œå…¶è´¨é‡è¡¨ç°æ›´å¥½")
            elif agent_quality > workflow_quality + 0.1:
                recommendations.append("æ™ºèƒ½ä½“æ¨¡å¼è¡¨ç°æ›´å¥½ï¼Œå¯ä»¥è€ƒè™‘æ‰©å¤§å…¶åº”ç”¨èŒƒå›´")
        
        # åˆ†æè´¨é‡è¶‹åŠ¿
        recent_trends = self.metrics['quality_trends'][-50:]  # æœ€è¿‘50ä¸ªä»»åŠ¡
        if recent_trends:
            recent_avg_quality = sum(t['quality'] for t in recent_trends) / len(recent_trends)
            if recent_avg_quality < 0.7:
                recommendations.append("æ•´ä½“è´¨é‡ä¸‹é™ï¼Œå»ºè®®æ£€æŸ¥æ¨¡å‹é…ç½®å’Œæç¤ºè¯")
        
        return recommendations
```

## ğŸš€ éƒ¨ç½²ä¸è¿ç»´

### æ··åˆç³»ç»Ÿé…ç½®

```python
from pydantic import BaseSettings
from typing import Dict, List

class HybridSystemConfig(BaseSettings):
    """æ··åˆç³»ç»Ÿé…ç½®"""
    
    # LLMé…ç½®
    llm_api_key: str
    llm_model: str = "gpt-4"
    llm_temperature: float = 0.7
    
    # è·¯ç”±é…ç½®
    auto_mode_enabled: bool = True
    quality_threshold: float = 0.8
    max_retries: int = 2
    
    # æ€§èƒ½é…ç½®
    max_parallel_workers: int = 4
    task_timeout_seconds: int = 60
    
    # ç›‘æ§é…ç½®
    enable_monitoring: bool = True
    alert_thresholds: Dict[str, float] = {
        'success_rate': 0.9,
        'average_quality': 0.7,
        'response_time': 30.0
    }
    
    # å·¥ä½œæµé…ç½®
    workflow_configs: Dict[str, Dict] = {}
    
    # æ™ºèƒ½ä½“é…ç½®
    agent_configs: Dict[str, Dict] = {}
    
    class Config:
        env_file = ".env"

# ä½¿ç”¨é…ç½®
config = HybridSystemConfig()
hybrid_system = IntelligentCustomerServiceSystem(llm_client)
```

## ğŸ“‹ æ€»ç»“

### æ··åˆæ¶æ„çš„æ ¸å¿ƒä¼˜åŠ¿

1. **æœ€ä½³å¹³è¡¡**: ç»“åˆå·¥ä½œæµçš„å¯é æ€§å’Œæ™ºèƒ½ä½“çš„çµæ´»æ€§
2. **æ™ºèƒ½è·¯ç”±**: æ ¹æ®ä»»åŠ¡ç‰¹æ€§è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„å¤„ç†æ–¹å¼
3. **æ¸è¿›ä¼˜åŒ–**: å¯ä»¥æ ¹æ®æ€§èƒ½åé¦ˆåŠ¨æ€è°ƒæ•´å¤„ç†ç­–ç•¥
4. **é£é™©åˆ†æ•£**: é™ä½å•ä¸€æ¶æ„çš„å±€é™æ€§é£é™©
5. **æˆæœ¬ä¼˜åŒ–**: åœ¨ä¿è¯è´¨é‡çš„å‰æä¸‹ä¼˜åŒ–èµ„æºä½¿ç”¨

### å®æ–½å»ºè®®

1. **ä»ç®€å•å¼€å§‹**: å…ˆå®ç°åŸºç¡€çš„è·¯ç”±é€»è¾‘ï¼Œå†é€æ­¥å¢åŠ å¤æ‚åŠŸèƒ½
2. **æ•°æ®é©±åŠ¨**: åŸºäºå®é™…ä½¿ç”¨æ•°æ®æ¥ä¼˜åŒ–è·¯ç”±ç­–ç•¥
3. **æŒç»­ç›‘æ§**: å»ºç«‹å®Œå–„çš„ç›‘æ§ä½“ç³»ï¼ŒåŠæ—¶å‘ç°å’Œè§£å†³é—®é¢˜
4. **ç”¨æˆ·åé¦ˆ**: æ”¶é›†ç”¨æˆ·åé¦ˆæ¥æ”¹è¿›ç³»ç»Ÿæ€§èƒ½
5. **å›¢é˜ŸåŸ¹è®­**: ç¡®ä¿å›¢é˜Ÿç†è§£æ··åˆæ¶æ„çš„è®¾è®¡ç†å¿µå’Œæ“ä½œæ–¹æ³•

### é€‚ç”¨åœºæ™¯

- **ä¼ä¸šçº§åº”ç”¨**: éœ€è¦åŒæ—¶å¤„ç†æ ‡å‡†åŒ–å’Œä¸ªæ€§åŒ–éœ€æ±‚
- **å®¢æˆ·æœåŠ¡**: ç»“åˆæ ‡å‡†æµç¨‹å’Œå¤æ‚é—®é¢˜è§£å†³
- **å†…å®¹å¹³å°**: å¹³è¡¡æ•ˆç‡å’Œåˆ›æ„è´¨é‡
- **æ•°æ®åˆ†æ**: ç»“åˆæ ‡å‡†æŠ¥å‘Šå’Œæ¢ç´¢æ€§åˆ†æ
- **æ•™è‚²åŸ¹è®­**: æ ‡å‡†åŒ–è¯¾ç¨‹å’Œä¸ªæ€§åŒ–è¾…å¯¼

---

> æ··åˆæ¶æ„ä»£è¡¨äº†AIç³»ç»Ÿè®¾è®¡çš„æœªæ¥æ–¹å‘ï¼Œå®ƒä¸æ˜¯ç®€å•çš„æŠ€æœ¯å †å ï¼Œè€Œæ˜¯å¯¹ä¸åŒAIèƒ½åŠ›çš„æ™ºèƒ½ç¼–æ’ã€‚æˆåŠŸçš„æ··åˆç³»ç»Ÿéœ€è¦æ·±å…¥ç†è§£ä¸šåŠ¡éœ€æ±‚ï¼Œç²¾å¿ƒè®¾è®¡è·¯ç”±ç­–ç•¥ï¼Œå¹¶æŒç»­ä¼˜åŒ–æ€§èƒ½è¡¨ç°ã€‚